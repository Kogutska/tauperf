#!/usr/bin/env python
import os
import pickle
# --> python imports
from  itertools import combinations
import fileinput

# --> rootpy imports
import rootpy
rootpy.log.basic_config_colorized()
from rootpy import asrootpy
from rootpy.io import root_open
from rootpy.extern import argparse
from rootpy.plotting.style import get_style
from rootpy.plotting import Hist, Hist2D, Canvas
# --> root imports
import ROOT
# --> local imports
from tools.datasets import DATASETS, VERSION
from tauid.trainer import BDTScan
from tauid.jobs import run_pool
from tauid import VARIABLES
from tauid import log; log=log[__name__]
from batch import qsub

ROOT.gROOT.SetBatch(True)

#--> Receive and parse argument
parser = argparse.ArgumentParser()
parser.add_argument("chunkname", help='list of input variables')
parser.add_argument("--pickle-file", help='pickle file name')
parser.add_argument('--sig-dataset', help='the signal dataset')
parser.add_argument('--bkg-dataset', help='the background dataset')
parser.add_argument("--factory-prefix", help="the basename of the training result", default='test')
parser.add_argument("--ID", help="the ID menu trained (full/presel)",
                    default='presel', choices=['presel', 'full'] )
parser.add_argument("--cat", help="the category used for training", default='all',
                    choices=['all', '1p', '3p', 'mp', '1p_0n', '1p_Xn', '3p_0n', '3p_Xn'] )
parser.add_argument("--object-type", help="the sample type", default="offline", choices=['EF', 'offline'])
parser.add_argument('--ntrees', default=100)
parser.add_argument('--nevts', default=5000)
parser.add_argument('--n-jobs', default=10)
parser.add_argument('--bkg-cut', default='')
parser.add_argument('--sig-cut', default='')

args = parser.parse_args()
parser.print_usage()

signal = DATASETS[args.sig_dataset]
background = DATASETS[args.bkg_dataset]
ecm = signal['ecm']

# --> Import signal and bkg trees
sig_tree = ROOT.TChain('tauCell_train')
bkg_tree = ROOT.TChain('tauCell_train')

for ifile in open(signal['path']):
    sig_tree.Add(ifile.strip())
for ifile in open(background['path']):
    bkg_tree.Add(ifile.strip())

log.info('-------- bkg cut --------')
bkgcut = ROOT.TCut(args.bkg_cut)
log.info(args.bkg_cut)
log.info('-------- sig cut --------')
sigcut = ROOT.TCut(args.sig_cut)
log.info(args.sig_cut)
chunks_dict = {}
with open(args.pickle_file) as file:
    chunks_dict = pickle.load(file)


workers = []

listes = chunks_dict[args.chunkname]
for name, sublist in listes.items():
    log.info(sublist)
    output_name  = 'tmp/{0}_{1}_{2}_{3}_{4}_nevts{5}_ntrees{6}_{7}.root'.format(args.factory_prefix, args.cat,
                                                                                ecm, args.object_type,
                                                                                args.ID, args.nevts, args.ntrees, name)
    factory_name = '{0}_{1}_{2}_{3}_{4}'.format(args.factory_prefix, args.cat,
                                                ecm, args.object_type, args.ID)
    log.info(factory_name)
    workers.append(BDTScan(output_name,factory_name,
                           sublist,
                           sig_tree, bkg_tree,
                           sigcut, bkgcut,
                           args.ntrees, args.nevts))
run_pool(workers, n_jobs=args.n_jobs)
